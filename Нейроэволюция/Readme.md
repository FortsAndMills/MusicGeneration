# NEAT

Собственно, статья:
http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf

Любительский эксперимент, отчасти вернувший интерес к алгоритму

https://www.youtube.com/watch?v=qv6UVOQ0F44

(автором, кстати, приложен код)

Доступное и на русском объяснение с примерами

http://nut-code-monkey.blogspot.ru/2016/04/NEAT-algorithm.html

## Дальнейшие развития 

http://www.natekohl.net/ut/pubs/papers/kohlgecco08.pdf

## Ещё интересные ссылки по нейроэволюции

Похоже, какой-то интересный складик

ftp://ftp.vt.tpu.ru/study/Spitsyn/public/from%20Tzoy/Neuroevolution/lectures/

Статья 2017 года по обучению нейронок "типа" генетическим (на самом деле, более банальным!) алгоритмом, которая сравнима по результатам с достижениями глубинок на Atari

https://blog.openai.com/evolution-strategies/

# ЭКСПЕРИМЕНТЫ:

## Готовая реализация под питон
NEAT-python
http://neat-python.readthedocs.io/en/latest/

Для запуска алгоритма требуется иметь в той же папке config-файл. В репозитории лежат config-feedforward (базовый пример) и first_exp.config, использовавшийся для проваленного теста с музыкой. 

NEAT-python умеет визуализировать получившуюся нейросетку при помощи graphviz-а, однако соответствующий модуль, модуль visualise.py, почему-то в сам пакет "не входит" и его надо хранить в одной папке с ноутбуком.

## Сам эксперимент

*Код: NEAT first experiments.ipynb*

На примере xor-а видно, что для нахождения этой нетривиальной булевой функции алгоритму требуется в среднем 13 поколений по 150 особей (это согласуется с иходной статьёй). Значение это колблется, иногда нужно 70 поколений, иногда результат неоптимален (в плане, что получившаяся нейросетка имеет кучу нейронов).

Для кузнечика шевелились параметры генерации и удаления новых узлов, параметры мутации весов и попробованы различные функции потерь. Также были переброваны самые разные reward-функции. При каком-то магическом наборе параметров удалось дождаться, пока на ~3000-ом поколении он дошёл до 27-ой доли песни (всего в песнях по 128 долей, первые 8 кладутся в память изначально).

При этом считалось, что клавиша нажата, если на соотв. выходе значение больше 1. Позже выяснилось, что это не соответствует оригинальной задумке алгоритма, и кнопки должны "зажиматься", если значение строго больше 0 (при отсутствии связей значение равно 0). Однако, такое изменение только ухудшило положение.

Если задуматься, то алгоритму требуется последовательно решать задачи аналогичные XOR-у, не ломая предыдущие достижения. Новые связи появляются в результате мутаций, и проводятся между случайными узлами. Известно, что имея изначально два входных нейрона, на одну такую задачу у алгоритма уходит более 10 поколений, здесь же входных нейронов 400+. 
