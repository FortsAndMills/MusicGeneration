# NEAT

### Собственно, источник вдохновения:
http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf

''Краткое саммари'': предлагается обучать нейросеть генетическим алгоритмом, однако генотипом является не только набор весов, но и закодированная нехитрым образом топология сети. Одним из видов мутации при этом становится добавление новой связи, при которой одновременно вся популяция получает по одному новому гену, соответствующую этой связи. При скрещивании эти связи могут появляться или исчезать. Авторы утверждают, что алгоритм не застрявает и всегда выбирается из промежуточных локальных минимумов за счёт стохастических преобразований топологии, а также их собственной эвристики "видов". Между нейронками вводится понятие расстояния, и популяция эвристически кластеризуется на "виды", которые некоторое время полностью защищены от вымирания. Таким образом авторы надеялись защитить эволюцию от удаления удачных вариантов сразу же после их появления до проявления их удачности через несколько поколений после дополнительной топологической надстройки; воспроизвести их успех на кузнечике мне (см. "эксперимент") не удалось... :( Вроде как, судя по xor-у (на нём у меня результаты сошлись), с логическими задачами эта штука справляется не очень, поэтому результат не удивителен.

### Доступное и на русском объяснение с примерами

http://nut-code-monkey.blogspot.ru/2016/04/NEAT-algorithm.html

### Фанатский эксперимент, отчасти вернувший интерес к алгоритму

После выхода этого видео, в сети снова появилось куча экспериментов с роботехникой на основе NEAT-а.
https://www.youtube.com/watch?v=qv6UVOQ0F44

Автором, кстати, приложен собственный код всего этого дела. Обучавшийся день NEAT научился проходить 1-ый уровень марио. Видно, что сеть у него получилась не сильно-то и глубокая, и интересный вопрос, что она будет делать на 2-ом уровне (при встрече новых объектов - ничего; а вот если все объекты известны, но конфигурая уровня поменяется?..).

### Дальнейшие развития 

http://www.natekohl.net/ut/pubs/papers/kohlgecco08.pdf

## Ещё интересные ссылки по нейроэволюции

### Генетика vs глубокое Q-обучение
Статья 2017 (!) года по обучению нейронок вариацией генетического алгоритма, которая сравнима по результатам с достижениями глубинок на Atari.

https://blog.openai.com/evolution-strategies/
(сама научная статья: https://arxiv.org/pdf/1703.03864.pdf)

'''Краткое содержание''': Новая популяция сэмплируется из распределения m + N(0, sigma * I), где m - текущее наилучшее решение, sigma задано, N - нормальное распределение. Особи оцениваются, после чего новое m = взвешанному среднему всех особей с весами из reward-ов. За этим есть некая математика, но вот что тут интересного: авторы признаются, что так просто это не работает, и хитрость в том, что нужно делать батч-нормализацию. Насколько я знаю, в слое нейронки перед применением функции активации значения входов нормируются. Якобы после этого всё у них взлетело. 

### CMA-ES, Генетическая оптимизация 

Презентация по алгоритму CMA-ES (Covariance Matrix Adaptation Evolution Strategy, 2001), который считается чем-то вроде топовым методом генетической эволюции как метода оптимизации чёрных коробочек.
https://www.lri.fr/~hansen/gecco2011-CMA-ES-tutorial.pdf

'''Кратко математически алгоритм''':
- Задача: оптимизировать чёрную коробочку. Умеем только считать значения в точках.
- Будем сэмплировать популяцию из m + sigma * N(0, C), m - условно наилучшее текущее решение, sigma - т.н. step-size, насколько широко хочется искать, N(0, C) - нормальное распределение с матрицей ковариации C.
- После оценки всех особей проапдейтим параметры m, sigma и C:
    - m берётся как взвешанное особей с весами из значений функции.
    - C апдейтится как максимизация правдоподобия в следующий раз сэмплировать те же особи, что и на текущем шаге, с весами из значений функции.
    - sigma в презентации апдейтится странновато, эвристика на сравнении пройденного расстояния и расстоянием между текущим положением и точкой старта в самом начале алгоритма.
- Результаты: якобы очень крут при небольшой размерности пространства.

### Практическое применение нейроэволюции в целом

Обозреваются разные методы на примерах игрушек, надо бы прочитать:
http://julian.togelius.com/Risi2015Neuroevolution.pdf

### Ещё ссылки

Похоже, какой-то интересный складик всякой всячины (интересно, откуда это? там что-то шибко умное!):
ftp://ftp.vt.tpu.ru/study/Spitsyn/public/from%20Tzoy/Neuroevolution/lectures/

# ЭКСПЕРИМЕНТЫ:

## Готовая реализация под питон
NEAT-python
http://neat-python.readthedocs.io/en/latest/

Для запуска алгоритма требуется иметь в той же папке config-файл. В репозитории лежат config-feedforward (базовый пример) и first_exp.config, использовавшийся для проваленного теста с музыкой. 

NEAT-python умеет визуализировать получившуюся нейросетку при помощи graphviz-а, однако соответствующий модуль, модуль visualise.py, почему-то в сам пакет "не входит" и его надо хранить в одной папке с ноутбуком.

## Сам эксперимент

*Код: NEAT first experiments.ipynb*

На примере xor-а видно, что для нахождения этой нетривиальной булевой функции алгоритму требуется в среднем 13 поколений по 150 особей (это согласуется с иходной статьёй). Значение это колблется, иногда нужно 70 поколений, иногда результат неоптимален (в плане, что получившаяся нейросетка имеет кучу нейронов).

Для кузнечика шевелились параметры генерации и удаления новых узлов, параметры мутации весов и попробованы различные функции потерь. Также были переброваны самые разные reward-функции. При каком-то магическом наборе параметров удалось дождаться, пока на ~3000-ом поколении он дошёл до 27-ой доли песни (всего в песнях по 128 долей, первые 8 кладутся в память изначально).

При этом считалось, что клавиша нажата, если на соотв. выходе значение больше 1. Позже выяснилось, что это не соответствует оригинальной задумке алгоритма, и кнопки должны "зажиматься", если значение строго больше 0 (при отсутствии связей значение равно 0). Однако, такое изменение только ухудшило положение.

Если задуматься, то алгоритму требуется последовательно решать задачи аналогичные XOR-у, не ломая предыдущие достижения. Новые связи появляются в результате мутаций, и проводятся между случайными узлами. Известно, что имея изначально два входных нейрона, на одну такую задачу у алгоритма уходит более 10 поколений, здесь же входных нейронов 400+. 
