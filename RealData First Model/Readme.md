Ниже представлено описание основных результатов эксперимента в формате "хачу результат".

## 03/12 - Первая рабочая модель на реальных данных.
[LSTM simple model.ipynb](https://github.com/FortsAndMills/MusicGeneration/blob/master/RealData%20First%20Model/%D0%A1%D0%B2%D0%B0%D0%BB%D0%BA%D0%B0%20%D1%8D%D0%BA%D1%81%D0%BF%D0%B5%D1%80%D0%B8%D0%BC%D0%B5%D0%BD%D1%82%D0%BE%D0%B2/LSTM%20real%20data%20simple%20model.ipynb)

* Помимо текущего вектора (размер одного вектора - 88) на вход подавались вектора 3, 7, 15, 31, 47, 63, 95 и 127 моментов времени назад. Это, наверное, самая банальная модель памяти, какую только можно придумать.
* Датасет разбивался на фрагменты по 256 моментов времени, старты с каждых двух тактов (такт - 16 моментов времени).
* Обработка однослойным LSTM-ом (300 нейронов).
* На выходе 88 вероятностей, с которыми нужно засэмпировать очередную ноту.

В принципе, это уже что-то. [](300 LSTM CM_dataset songs by fragments 8-history 12000 steps lr=0.01.mid)
