{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! out of range!\n",
      "ERROR! out of range!\n",
      "ERROR! out of range!\n"
     ]
    }
   ],
   "source": [
    "from songs import *\n",
    "\n",
    "import copy\n",
    "def addAllTransposedVersions(Songs, song):\n",
    "    while song.transpose(1):\n",
    "        pass\n",
    "\n",
    "    Songs.append(copy.deepcopy(song))\n",
    "    while song.transpose(-1):\n",
    "        Songs.append(copy.deepcopy(song))\n",
    "        \n",
    "Songs = []\n",
    "for i in range(1, 35):\n",
    "    addAllTransposedVersions(Songs, Song('basic midi/track (' + str(i) + ').mid'))\n",
    "    \n",
    "all_songs = np.array([song.notes for song in Songs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate():\n",
    "    X = np.random.randint(0, 2, (128, 128+64, 13))\n",
    "    X[:, 128:, :] = 0\n",
    "    Y = np.zeros((128, 128+64, 13))\n",
    "    Y[:, 64:, :] = X[:, :128, :]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "training_steps = 10000\n",
    "batch_size = 128\n",
    "display_step = 200\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 13\n",
    "timesteps = 128+64 # timesteps\n",
    "num_hidden = 50 # hidden layer num of features\n",
    "history_size = 80\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [batch_size, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [batch_size, timesteps, num_input])\n",
    "\n",
    "loss_op = tf.constant(0.0)\n",
    "\n",
    "read_lstm = tf.contrib.rnn.BasicLSTMCell(num_hidden, forget_bias=1.0, reuse=None)\n",
    "read_lstm_state = tf.zeros([batch_size, num_hidden]), tf.zeros([batch_size, num_hidden])\n",
    "\n",
    "read_w = tf.Variable(tf.random_normal([num_hidden, history_size]))\n",
    "read_b = tf.Variable(tf.random_normal([history_size]))\n",
    "\n",
    "history = tf.zeros([batch_size, num_input, history_size])\n",
    "\n",
    "delete_lstm = tf.contrib.rnn.BasicLSTMCell(num_hidden, forget_bias=1.0, reuse=True)\n",
    "delete_lstm_state = tf.zeros([batch_size, num_hidden]), tf.zeros([batch_size, num_hidden])\n",
    "\n",
    "delete_w = tf.Variable(tf.random_normal([num_hidden, history_size]))\n",
    "delete_b = tf.Variable(tf.random_normal([history_size]))\n",
    "\n",
    "write_lstm = tf.contrib.rnn.BasicLSTMCell(num_hidden, forget_bias=1.0, reuse=True)\n",
    "write_lstm_state = tf.zeros([batch_size, num_hidden]), tf.zeros([batch_size, num_hidden])\n",
    "\n",
    "write_w = tf.Variable(tf.random_normal([num_hidden, history_size]))\n",
    "write_b = tf.Variable(tf.random_normal([history_size]))\n",
    "\n",
    "_X = tf.unstack(X, timesteps, 1)\n",
    "_Y = tf.unstack(Y, timesteps, 1)\n",
    "for t, inp, truth in zip(np.arange(timesteps), _X, _Y):\n",
    "    read_lstm_output, read_lstm_state = read_lstm(inp, read_lstm_state)\n",
    "    \n",
    "    read = tf.sigmoid(tf.matmul(read_lstm_output, read_w) + read_b)\n",
    "    read_proba = tf.nn.softmax(read, 1)\n",
    "    loss_op -= tf.reduce_mean(tf.log(read_proba) * read_proba)\n",
    "    memory_retrieve = tf.matmul(history, tf.expand_dims(read, 2))\n",
    "    if t >= 64:\n",
    "        loss_op += tf.reduce_mean(tf.squared_difference(tf.squeeze(memory_retrieve, 2), truth))\n",
    "        \n",
    "    delete_lstm_output, delete_lstm_state = delete_lstm(inp, delete_lstm_state)\n",
    "    \n",
    "    delete = tf.sigmoid(tf.matmul(delete_lstm_output, delete_w) + delete_b)\n",
    "    delete_proba = tf.nn.softmax(delete, 1)\n",
    "    loss_op -= tf.reduce_mean(tf.log(delete_proba) * delete_proba)\n",
    "    history = history * tf.expand_dims(delete, 1)\n",
    "    \n",
    "    write_lstm_output, write_lstm_state = write_lstm(inp, write_lstm_state)\n",
    "    write = tf.sigmoid(tf.matmul(write_lstm_output, write_w) + write_b)\n",
    "    write_proba = tf.nn.softmax(write, 1)\n",
    "    loss_op -= tf.reduce_mean(tf.log(write_proba) * write_proba)\n",
    "    history = history + tf.tile(tf.expand_dims(inp, 2), [1, 1, history_size]) * tf.expand_dims(write, 1)\n",
    "\n",
    "# Define loss and optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = tf.contrib.layers.optimize_loss(\n",
    "    loss_op, tf.contrib.framework.get_global_step(), optimizer=optimizer,\n",
    "    learning_rate=learning_rate)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Minibatch Loss= 89.6539\n",
      "Step 200, Minibatch Loss= 87.4312\n",
      "Step 400, Minibatch Loss= 87.1355\n",
      "Step 600, Minibatch Loss= 86.8927\n",
      "Step 800, Minibatch Loss= 86.1247\n",
      "Step 1000, Minibatch Loss= 87.0389\n",
      "Step 1200, Minibatch Loss= 86.9196\n",
      "Step 1400, Minibatch Loss= 86.8620\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-eb70ad742e60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Run optimization op (backprop)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# Calculate batch loss and accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "sess = tf.Session()\n",
    "# Run the initializer\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(0, training_steps):\n",
    "    batch_x, batch_y = generate()\n",
    "    batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "    batch_y = batch_y.reshape((batch_size, timesteps, num_input))\n",
    "    \n",
    "    # Run optimization op (backprop)\n",
    "    sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "    if step % display_step == 0:\n",
    "        # Calculate batch loss and accuracy\n",
    "        L = sess.run(loss_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "        print(\"Step \" + str(step) + \", Minibatch Loss= \" + \"{:.4f}\".format(L))\n",
    "\n",
    "print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mr = sess.run(memory_retrieve, feed_dict={X: batch_x, Y: batch_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
