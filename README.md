## Глобальная задача

[Подходы к генерации музыки](https://github.com/FortsAndMills/MusicGeneration/tree/master/%D0%9F%D0%BE%D0%B4%D1%85%D0%BE%D0%B4%D1%8B%20%D0%BA%20%D0%B3%D0%B5%D0%BD%D0%B5%D1%80%D0%B0%D1%86%D0%B8%D0%B8%20%D0%BC%D1%83%D0%B7%D1%8B%D0%BA%D0%B8) - сборник ссылочек по этой теме. Нас конкретнее интересует именно генерация midi-файла. Глобально подходов два: просто что-нибудь придумать, основываясь на муз. теории, или запихнуть много данных в нейросеть.

## Работа с midi в питоне
Существует много библиотек под питон, я использую [mido](https://mido.readthedocs.io/en/latest/).

Во всех экспериментах используется songs.py - простенький модуль, который пока может:
* загружать миди-файлы
* проверять их на то, что они не выходят за диапазон
* проигрывать их прямо в ноутбуке
* переводить в булев массив [время x количество клавиш], пока без квантизации
* создавать новый миди-файл по передаваемым строкам булева массива
* вносить в ноты "ошибки" примитивным алгоритмом

## Данные

На коленке было записано [34 песенки](https://github.com/FortsAndMills/MusicGeneration/tree/master/basic%20midi) из сборника произведений для первоклашек. Первая дорожка - кузнечик, с которого обычно и начинают.
* три из них выходят за диапазон в 13 клавиш; ещё несколько выходят за диапазон, но модуль songs транспонированием автоматически это исправляет
* если стартовать с инициализации памяти первым тактом, то будут "пересечения" - первый такт у нескольких мелодий совпадает.
* ещё есть песенка whomadethis.mid, которая как-то не очень похожа на музыку, но какой-то человек её умудрился написать. Предлагается оставить для валидации))

Это, конечно, для тестов, при готовности модели можно запихнуть в неё авторскую коллекцию от интернет-анонимусов midi из 600 000 файлов различной продолжительности и жанра, которую, правда, сначала надо будет пофильтровать; рандомные произведения вроде музыка. Есть ещё несколько коллекций разного объёма и жанра из разных источников, в общем найти много миди это не проблема.

# Упрощённая задача

Пока возьмём только 13 клавиш (одна октава + верхняя до, в стандартных обозначениях - C, C#, D, D#, E, F, F#, G, G#, A, A#, B и ещё одна C). В каждый момент времени клавиша либо нажимается, либо отпущена (т.е. понятия зажатой клавиши нет).

Также пока предположим отсутствие реккурентности; вместо памяти будем подавать на вход не только текущий, но и предыдущие моменты времени (скажем, 4 такта; вроде оптимально, кстати, будет брать 1, 2, 4, 8 и т.д. до некоторого предела).

## Переобучение vs запоминание

Первоначальная идея была реализовать обучение с подкреплением (нейросеть на кучи данных, выдающая reward ("слушатель") + "исполнитель", обучающийся на этом reward-е через Q-обучение или нейроэволюцию). Сильно упростим эту задачу: хотим всего лишь научить исполнителя играть кузнечика.

- если алгоритм детерминирован, то на входе, совпадающий с началом выученной песенки, он в точности повторит её без вероятности придумать другое продолжение. Есть способы обойти это - дополнительный вход, равный 1 при изучении песни, который при желании "импровизировать" выключается.
- а вот на новом входе алгоритм теоретически может выдать что-то ещё. Если запоминание обучающей выборки происходит каким-то образом с выделением закономерностей и знаний, то так может и что-то получится на выходе.
- в конце концов, если мы не можем решить эту задачу для "исполнителя" ("нажми вот эти кнопки в заданной последовательности и никак иначе"), то что уж говорить о задаче "а ну, играй на 13 кнопках то, что слушатель посчитает музыкой".

# NEAT

[Нейроэволюционный подход](https://github.com/FortsAndMills/MusicGeneration/tree/master/%D0%9D%D0%B5%D0%B9%D1%80%D0%BE%D1%8D%D0%B2%D0%BE%D0%BB%D1%8E%D1%86%D0%B8%D1%8F) хорош тем, что якобы умеет учиться нажимать кнопки (в данном случае - клавиши) в правильной последовательности. Однако пока что заставить его построить нейросеть, которая запомнит даже первые несколько тактов, [не удалось](https://github.com/FortsAndMills/MusicGeneration/tree/master/%D0%9D%D0%B5%D0%B9%D1%80%D0%BE%D1%8D%D0%B2%D0%BE%D0%BB%D1%8E%D1%86%D0%B8%D1%8F#ЭКСПЕРИМЕНТЫ) :( Возможно, я криворукий. 

Поэтому исследование ВНЕЗАПНО приняло неожиданный оборот:

# Булевоалгебраический подход

Тут уже нужен TeX, поэтому подробное полное описание и все идеи занесены в [общую презентацию](https://github.com/FortsAndMills/MusicGeneration/blob/master/Discon/%D0%A1%D0%BE%D0%B1%D1%80%D0%B0%D0%BD%D0%B8%D0%B5%20%D1%81%D0%BE%D1%87%D0%B8%D0%BD%D0%B5%D0%BD%D0%B8%D0%B9...%20%D0%B3%D0%BC%2C%20%D0%B1%D1%83%D0%BB%D0%B5%D0%B2%D1%8B%D1%85.pdf).

Для тех, кому лень смотреть презентацию, вот лаконичная интерпретация идеи от А.Думбая (2017):

![alt text](https://github.com/FortsAndMills/MusicGeneration/blob/master/Discon/Opinion.gif)

# Нейросети слона-суицидника

Происходящее [в этом разделе](https://github.com/FortsAndMills/MusicGeneration/tree/master/Elephant%20Neural%20Nets) отлично отражено в последнем слове названия... Но хочется научиться строить типа-нейросеть, выдающую правильный ответ на заданных объектах. Это в некотором смысле обобщение подхода с булевыми функциями.

Глобальная проблема подхода - непонятно, как выбирать действие так, чтобы равномерно случайно спускаться вглубь сети. В целом эту проблему решить удалось (вводим качество связей -> уверенность сигнала нейрона оцениваем как минимальное произведение качеств связей на пути до него -> это примерно экспоненциальное падение уверенности -> с конца шагаем к началу с вероятностями "уверенности сигнала"), а вот следующий глобальный шаг - сбалансировать рост и удаление нейронов - пока не удался.

# Пытаемся не думать о слонах

[Забавный эксперимент](https://github.com/FortsAndMills/MusicGeneration/blob/master/two%20neurals.ipynb). Для нас закономерность ABABAB... одна из самых простых. Но обычные нейронки так не считают... В эксперименте одна нейронка (Q-агент) каждый ход нажимает одну клавишу из тринадцати так, чтобы скайлёрновский MLPClassifier угадывал это, но неидеально. Если угадывание идеально, то штраф начинает экспоненциально расти, выпинывая товарищей из ямы. Пока иногда сходится к выдаче одной и той же клавиши, но всё это кривоватенько выглядит и непохоже, что они выберутся из этого локального оптимума и тем более придумают ABABAB.

Конечно, машинное обучение уже придумало, как учить модель считать. Классика - LSTM, но есть и более специфичные варианты, подробнее вот [в этом разделе](https://github.com/FortsAndMills/MusicGeneration/tree/master/%D0%9F%D0%BE%D0%B4%D1%85%D0%BE%D0%B4%D1%8B%20%D0%BA%20%D0%B3%D0%B5%D0%BD%D0%B5%D1%80%D0%B0%D1%86%D0%B8%D0%B8%20%D0%BC%D1%83%D0%B7%D1%8B%D0%BA%D0%B8#А-что-ещё-тут-не-пробовали). 

Из пощупанного - GAN на мнисте, после подмены данных простой эксперимент в лоб выдаёт быструю сходимость к одной из песен, что с одной стороны понятно (нейросеть + мало данных), а с другой интересно, почему проходы по другим песням не вышибают сеть из локального оптимума.

Ещё [одна затея](https://github.com/FortsAndMills/MusicGeneration/blob/master/Autoencoder%20XtoX%20transformations%20test.ipynb): будем считать, что есть набор хороших примеров, и одни примеры можно получать из других некоторыми преобразованиями. Хочется найти преобразование. Вообще, хочется найти такую функцию f, что f(X_i) = X_j для некоторого j != i. Не будем думать о слонах и попробуем сформулировать это в терминах задачи для непрерывной оптимизации... А f приблизим нейронкой (под рукой была топология автокодировщика). Пока ерунда, f сходится к константе, по функционалу равномерно удаленной от всех объектов выборки.

Последние два эксперимента закончились схлопыванием генератора к константе. Оказывается, на больших датасетах такое вполне себе тоже часто встречается и является повсеместной проблемой. Решением является довольно вставная вещь, т.н. Minibatch discrimination, с имплементацией придётся повозится (а может, получше поискать готовые решения).

# Двигаемся в направлении LSTM-а
Ну окей-окей, раз слонами задачу не решить, и нужно действовать по-научному, то LSTM-таки нужно достать, и делать им одно из двух: или пытаться строить предикат музыки (то есть "слушателя" в терминах идей выше), или, по классике, генератор. Попробовал на, кхм, 35 песенках первое; батч составляется так: с высокой вероятностью берётся неизменное исходное произведение с таргетом 1, а с экспоненциально падающей в него добавляются "ошибки" - случайные подмены нот и пр., что определённо всё ломает. Таргет при этом соответственно падает, и задачей LSTM-а по сути становится задача регрессии, насколько именно данные "испорчены". Естественно, lstm обучается, а дальше можно делать а) пытаться из шума градиентным спуском сойтись к чему-то, у чего будет высокий отклик сети (>> 1...), минусы - ноты становятся непрерывными, но казалось бы это самый грамотный подход; б) генетический пооооиск! Плюсы - ноты всё-таки будут 0 и 1. Сходится к вариантам с кучей единиц или одним нулям, т.е. вещам, которых в выборке в помини не было. Видимо, надо добавить в выборку нагенерированных примеров от балды.

### Модели с памятью
Так-так-так, меня тут ткнули носом в неправильное понимание тюрьинг-нейронок. Возможно, это именно то, что нам нужно! Подробнее о тьюринг-нейронках в разделе со статьями, научная (кхм) мысль же пока такая: lstm умеет генерировать музыку, но не очень. Почему не очень - а например, потому что не умеет запоминать целиком целые фрагменты. Как раз эту проблему решают тьюринг-нейронки, значит, давайте lstm менять на них.

## Эксперименты
LSTM действительно не воспринимает такую закономерность, как повтор, и это ключевая проблема. Попытка добавить в сеть внешнюю память, HistoryUser, пока успехом не увенчалась - не сходится к нужным параметрам (впрочем, неудивительно... тогда почему работает тьюринг?). Есть менее костыльная, но технически сложная в реализации затея следующего вида. Нужно научить модель повтору. Значит, нужно иметь нечто, что будет говорить нейросети, что знаешь, ты уже была вот в том "состоянии", в котором ты сейчас находишься, и правильный ответ тогда был вот такой. Другая интерпретация - память модели есть ещё одна переобученная модель. Например, 1NN. Здесь есть некие параллели с тьюринг-нейронкой, и по этой затеи есть ещё комментарии, но с реализацией пока тех.проблемы и лобовой эксперимент пока не провёл.
