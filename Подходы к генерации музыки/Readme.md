# Собсно, нейросети

### Через LSTM
Лобовой вариант - превратить всё в текст и кинуть в LSTM, обычно тут так и делают.
http://people.idsia.ch/~juergen/blues/IDSIA-07-02.pdf

### Ещё через LSTM

https://geektimes.ru/post/259958/

### Фанатский LSTM
Фанатская попытка сочинять через RNN, без особой науки. Товарищ, однако, откопал abc-нотацию, в которой также местами помечены гармонии, в результате сеть явно в них начала разбираться.
https://maraoz.com/2016/02/02/abc-rnn/

### Основано всё это на генерации текстов...

Классические статьи про "а смотрите-ка, что умеют реккурентные нейросети":

2011: http://www.cs.utoronto.ca/~ilya/pubs/2011/LANG-RNN.pdf

2010: http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf

### Полезное про сам LSTM

Отличная статья простым языком:

http://colah.github.io/posts/2015-08-Understanding-LSTMs/

По сути LSTM - это имитация возможности "записи" и "чтения" в память нейрона, что позволяет хранить информацию в сети потенциально сколь угодно долго (но увы, см. vanishing gradients, не знаю как это грамотно на русский)

### Немного нейроэволюции:

Эксперимент довольно безумный, использовалась однослойная нейросеть, в которой генетикой отбирались нейроны в нём (генотип - набор входных связей в нейрон). Что-то даже вышло.
http://nn.cs.utexas.edu/downloads/papers/chen.ijcnn01.pdf

### Последние достижения Magent-ы (от авторов, подаривших нам tensorflow...)

PerformanceRNN представляет собой отказ от МИДИ-дискретизации, берёт 10ms-ый интервал между событиями, и за счёт этого позволяет играть несколько нот как бы почти сразу. А вот ритм сеть должна выучить сама... Результат пока наиболее впечатляющий (см. онлайн-версию), но дольше нескольких тактов в одной "песне" пребывать сеть не умеет, и данные из прошлого не использует. Впрочем, с миди-дискретизацией пока тоже особо ничего не получилось...

https://magenta.tensorflow.org/performance-rnn

# А что ещё тут не пробовали?

С высоты птичьего полёта по последним достижениям человечества:
https://distill.pub/2016/augmented-rnns/

### Generative Adversarial Networks

GAN вообще самая, похоже, модная тема в последнее время в области генерации, за ней стоит прикольная идея. Одна нейронка обучается генерировать, начиная с генерации ерунды, вторая учится различать результаты первой нейросети от подлинных изображений. Вторая решает задачу классификации, первую можно обучать на основе градиентов при подстановке во вторую.

https://arxiv.org/pdf/1511.06434.pdf

Оказывается, проблема схлопывания генератора к объектам из набора примеров типична для такой схемы. Поэтому, нужно делать ещё один шаг под названием minibatch discrimination, описано здесь: https://arxiv.org/pdf/1606.03498.pdf.

Подробный обзор того, чего добились генеративные модели подобным подходом: https://blog.openai.com/generative-models/

С музыкой проблема в том, что пока непонятно, как считерить так, чтобы сымитировать долговременную память.

### -> управление вниманием
### Тьюринг-нейронки

https://arxiv.org/pdf/1410.5401.pdf

Последние сводки показывают, что это, возможно, очень важная статья. Ключевая решённая в статье проблема - задача копирования, нужно выдать такую же последовательность, как и та, которую подают на вход. Для этого нужно иметь память и запоминать вход. По сути, у сети есть внешняя память, из которой он может считывать и в которую может писать, при чём все функции дифференцируемы и, что главное, локальны, чем сеть добивается считывания именно конкретных участков из памяти (и в этом месте авторы словно перемудривают, но похоже, что на то есть веские причины, пока не понял), а не линейной комбинации всего в неё позаписанного.

#### Апгрейд

Не всё тут так просто, поэтому дальше над ней как-то ещё колдуют, надо разбираться.

https://arxiv.org/pdf/1612.02336.pdf

### Генерация стульев

Ну, с картинками что-то почему-то у всех всё получается...
https://arxiv.org/pdf/1411.5928.pdf

### Генерация текстур

Более прямое отношение к музыке, т.к. в текстурах есть повторы и вариации. Правда, за основу взята сеть-классификатор, а что классифицировать в музыке непонятно. Кратко идея: проводить шум так, чтобы минимизировать отличие между матрицами Грама внутри слоёв нейросети, якобы достаточная информация о данных содержится в них (что у меня вызывает вопрос "да ладно?", однако работает).

https://arxiv.org/pdf/1505.07376.pdf

### -> Google DeepDream

Классифицровали на котиков и собачек, пустили котика, посмотрели на активировавшиеся нейроны последнего слоя и сказали "хотим тут ещё больше!". Вот такое "сказали", подменяющее функцию потерь при обучении нейросети, позволяет дорисовывать этих самых котиков на любом входе.

### Самоорганизующиеся карты Кохонена...
Добавил сюда до кучи, потому что в паре мест наткнулся на этот алгоритм в контексте обсуждения нейроэволюции, что немного странно, так как отношение к ней он имеет посредственное. Хотя - итеративный проход по выборке, всё такое. Ну, во-первых, это алгоритм обучения без учителя для задачи кластеризации и проецирования на двумерную плоскость пространства признаков. В принципе-то прикольно, например есть желание в одном слое нейросети сливать коррелирующие нейроны. Может, Кохоненом кластеризовать нейроны в слое? не стреляйте в меня

# Связанные материалы

### Сборники ссылок по теме

Описание основных инструментов алгоритмической генерации музыки

http://www.asimovinstitute.org/analyzing-deep-learning-tools-music/

Компиляция open-source проектов по генерации музыки сетями

http://www.datasciencecentral.com/profiles/blogs/using-machine-learning-to-generate-music

### Алгоритмическая генерация

Автогенерация музыки (rus!). Просто магия с паттернами, без обучения

http://armaxis.ru/files/MusicGenerator.pdf

На этом автогенерация не останавливается, и учёные идут дальше

https://habrahabr.ru/post/185606/

Есть и другие алгоритмические идеи...

http://www.insota.com/fileadmin/publications/Evolutionary-Search-for-Musical-Parallelism.pdf

### Связанные задачи

Генерация музыкальных аудиформ, даже без фурье.
https://cs224d.stanford.edu/reports/NayebiAran.pdf

Генерация вокодера (имитации живого пения). Тут так пока и не понял, что тут внутри, вроде как и тут без особого прогресса
http://www.dtic.upf.edu/~mblaauw/MdM_NIPS_seminar/files/poster.pdf
