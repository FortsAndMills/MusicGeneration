# Слоновьи нейросети...

## Идея

* есть задача запоминания выборки (в продолжение [вот этой философии](https://github.com/FortsAndMills/MusicGeneration/tree/master/Discon))
* предлагается попробовать решить её в нейросетевых терминах

### Мотивация:
* формулы, получающиеся в [булевом подходе](https://github.com/FortsAndMills/MusicGeneration/blob/master/Discon/%D0%A1%D0%BE%D0%B1%D1%80%D0%B0%D0%BD%D0%B8%D0%B5%20%D1%81%D0%BE%D1%87%D0%B8%D0%BD%D0%B5%D0%BD%D0%B8%D0%B9...%20%D0%B3%D0%BC%2C%20%D0%B1%D1%83%D0%BB%D0%B5%D0%B2%D1%8B%D1%85.pdf) очень напоминают нейросеть
* любой алгоритм над булевыми входами или булевыми выходами может быть задан булевой формулой, поэтому нейросеть с булевыми входами и выходами можно попытаться строить логическим путём
* нейросетям свойственно дообучение => возможность "выучивать" новые данные
* топологические преобразования могут быть интерпретируемой дискретной заменой градиентной оптимизации
* нейроны в данной концепции превращаются в нечто вроде "понятий", т.е. терминологического языка, которым сеть описывает явления в выборке

### Мечты:
* алгоритм сам оценивает сложность данных и строит столько нейронов и связей, сколько нужно
* в процессе запоминания алгоритму сложность построить вырожденные случаи переобучения (а-ля 1NN), вместо этого ему придётся придумывать правила, отсекать неудачные и оставлять удачные варианты, а т.е. выявлять закономерности
* вообще, в алгоритме нигде явно не требуется явного разделения X и y. Достаточно указать, какие события имели место быть, после чего во всех нейронах, где ожидания алгоритма не совпали с реальностью, проходить корректировка.

## Модель

Пусть количество булевых входов и выходов фиксировано, и имеется выборка. Связей и скрытых слоёв в сети нет; это стартовая инициализация.

Нейроны устроены стандартным образом, проводится суммирование входов и сравнение с нулём (функция Хэвисайда). Возможные альтернативы:  ReLu вместо функции активации; нейроны-диъюнкции и нейроны-конъюнкции; нефиксированный порог (т.е. изменение порога как потенциальное действие при корректировке).

Все веса связей равны 1 или -1 (альтернатива с 0 и 1 требует введения нейронов с отрицаниями).
